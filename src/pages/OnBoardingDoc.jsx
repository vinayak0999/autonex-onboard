import React, { useState } from 'react';

// ========================================================================
// 1. ANNOTATION Q&A CONTENT (11 Pages)
// ========================================================================
const qaPageContent = {
  1: {
    title: "What You Will Do",
    content: `There is a client model that performs tasks based on the given prompt.
The model goes through different websites, checking and performing actions as required by the task.
It completes the process step-by-step, starting with its thoughts (what it plans to do next) and continuing through actions until it concludes with a final output.
• During this step-by-step execution, the model might make mistakes or errors in its reasoning or actions.
• These mistakes can cause the trajectory to divert from the correct path, leading to task failure.

Your role as an annotator is to:
• Review the entire trajectory of the model (its thoughts and actions).
• Identify where the error happened and what type of error it is using the Error Categorization (EC) document.
• Mark the main cause of failure — the specific error that led the model to go wrong.
• If the model succeeded, ensure the process was correct and complete.
• If it failed, find and label the exact reason for failure, not just the symptoms.

The goal is to make sure that each model trajectory is evaluated correctly, so that the model can be improved and retrained based on your feedback.`
  },
  2: {
    title: "Reading the Error Categorization Doc",
    content: `Why You Should Read the EC Example Library

The EC Example Library explains all the error types a model can make while performing a task.
It helps you learn how to identify and mark errors correctly during annotation.

The document includes:
➤ Definitions of each error
➤ Key points to check before marking
➤ Examples of correct and incorrect cases

It covers all the main areas from
Prompt Errors,
Incorrect / Missed Model Actions,
Incorrect / Missed Model Thoughts,
Output errors,
Infrastructure Errors(Non-Model Fault Errors), Tool Error

Reading it will help you make accurate, consistent, and confident decisions while evaluating model trajectories.`,
    docs: [
      { name: 'EC Example Library Doc', url: 'https://docs.google.com/document/d/1yamEzJSFuvaKpWvDoB4mVGo14eMCwUtEFdkr5_8w27s/edit?tab=t.0#heading=h.dwbjqcnuj2m' },
      { name: 'Autonex guidelines / steps by EC', url: 'https://docs.google.com/document/d/1tLN9XC66BWfWU_2YMv3fM7M14B4xFal_rlrbj34Muzs/edit?tab=t.0#heading=h.qkseevawdd8' }
    ]
  },
  3: {
    title: "Cases",
    content: `Depending on the task, error, and model's output, you have to decide the final conclusion of the task.

There are four possible cases:

1. Success - Task completed correctly.

2. Failure - Task not completed or result incorrect.

3. Cannot Be Determined - Task can't be verified due to missing or outdated info.

4. Accidental Success – Correct result but achieved by chance or wrong reasoning.
    
The following table:`,
    image: 'img1'
  },
  4: {
    title: "Task Status Definitions",
    content: `Task Status | Definition | An efficient way of writing a status explanation

FAILURE:
The prompt requirements are not met. The model's summary includes incorrect, hallucinated, or misleading information or links. Any mistake in the output must result in marking this as a failure. When the model says, 'it couldn't do the process, mark the task as failure'

• Clearly state the number of results returned by the model (if applicable)
• Explain how the identified error(s) impacted the model's trajectory and final output.
• Highlight the discrepancy between the model output and manual verification.
• End with a conclusive statement confirming the task is a "Failure".

SUCCESS:
The prompt requirements are fully satisfied. The content in the summary is completely accurate and verifiable.

• Mention the number of results generated by the model (if applicable).
• Briefly explain how the model fulfilled the prompt requirements.
• Support the result using manual verification evidence.
• End with a conclusive statement confirming the task is a "Success".

ACCIDENTAL SUCCESS:
Cases where the model returns zero results without conducting thorough research or following the expected trajectory, but manual verification confirms that zero results are indeed the correct answer.

• Mention that the model gave 0 results
• Briefly explain how the model failed to follow the expected reasoning or action steps.
• Explain how manual verification confirms the absence of results.
• Conclusive statement confirming the task is an "Accidental Success".

CANNOT BE DETERMINED:
Applicable when the prompt contains requirements that the model cannot fulfill due to technical limitations or ambiguity. Common scenarios include: prompts requiring audio/video interpretation, booking tickets for past events, logging into private accounts, or when the prompt lacks sufficient clarity.

• Mention the number of results, if any, returned by the model
• Briefly explain why the prompt is unanswerable or ambiguous
• Reference manual verification to confirm the task is indeterminate
• Conclusive statement confirming the task status is "Cannot be determined"

• If the prompt is bad, this default cannot be determined`
  },
  5: {
    title: "What is Critical Error",
    content: `• A Critical Error is the main mistake that caused the model to fail the task.
• It is the root cause of the failure — the step where things actually went wrong.
• Even if multiple small errors are present, you must find and mark the one key error that directly led to the task failure.
• Identifying the correct critical error helps ensure accurate evaluation and a clear understanding of why the model failed.
• Critical Error can be one or more than one
• Critical Error is same as the primary error (Both are same)

How to write the Critical error and the Step errors:`,
    image: 'img2'
  },
  6: {
    title: "Trajectory Status",
    content: `• The Trajectory Status represents the overall quality of the model's process (all steps except the final one).

Marking Rules:

• If Task Status = Success → Select Success

• If Task Status = Cannot be Determined → Select Cannot be Determined

• If Task Status = Failure →
○ If the critical error is in the last step only (for example, Summarization Failure or Dissatisfactory Output),
  → Mark the Trajectory Status as "Success".
○ If the critical error occurs anywhere in the middle or earlier part of the trajectory (i.e., during process steps and not in the final step),
  → Mark the Trajectory Status as "Failure".`
  },
  7: {
    title: "Auto Eval",
    content: `AutoEval (Automatic Evaluation) is a system that automatically reviews model outputs using predefined rules and logic.

It helps to speed up evaluations by predicting whether a model's output is Success or Failure.

AutoEval checks things like:
• If the model met the main task requirements.
• If key information is missing or incorrect.
• If the final output format or reasoning is wrong.

However, AutoEval is not always 100% accurate — it can miss context or misunderstand certain cases.

That's why human annotators still review each task to verify or correct AutoEval's decision.

If the annotator's judgment disagrees with AutoEval, they must recheck carefully and provide reasoning for their decision.`,
    docs: [
      { name: 'Autoeval EC (AE EC) Library', url: 'https://docs.google.com/document/d/1GrulVN1bF7erycM0plTt4VNnqhuRfTHhAe47cSb1-r4/edit?tab=t.0#heading=h.7m2r791gohwt' }
    ]
  },
  8: {
    title: "Moving Towards Practical Understanding",
    content: `Now that you've learned the basics about the platforms, documentation, and key terms, Let's move to the actual example to understand how everything works together — step by step.

In this part, you'll see:
1. How a task or prompt is given to the model.
2. How the model performs actions and generates steps (the trajectory).
3. How you, as an annotator, review those steps and identify if any errors occurred.
4. How to mark the critical error, decide the task status, and assign the trajectory status.

This walkthrough will help you understand the complete flow of annotation — from model execution to final evaluation.`
  },
  9: {
    title: "Video 1: Introduction To Encord and Yutori Platforms",
    content: `This video gives a brief introduction to the Yutori and Encord platforms.
• You will learn what each platform is used for and how they work together in the annotation process.
• It explains:
○ The purpose of both platforms.
○ How to navigate through them.
○ Basic functions like viewing trajectories, marking errors, and submitting evaluations.

Goal:
By the end of this video, you'll understand the role of Yutori and Encord in model evaluation and how to use them effectively during annotation.`,
    videos: [
      { name: 'Video 1 - Introduction to Encord', url: 'https://drive.google.com/file/d/1fjbC8MeyBfmUL5ZWofzoR-UXbmSgWEo6/view?usp=drive_link', thumb: 'video1_thumb' }
    ]
  },
  10: {
    title: "Video 2: Reviewing Process For Autonex QC",
    content: `This video explains the step-by-step review process followed in Autonex QC.
• You will learn how to check annotations, verify marked errors, and ensure quality and consistency in evaluations.
• It covers:
○ How to open and review trajectories.
○ How to confirm or correct the annotator's marked errors.
○ What to look for during Quality Check (QC) — accuracy, reasoning, and alignment with the EC guidelines.

Exact process for review
Goal:
By the end of this video, you'll understand how to perform quality checks in Autonex, maintain annotation standards, and provide clear feedback to annotators.`,
    image: 'img3',
    videos: [
      { name: 'Video 2 - Autonex QC Reviewing Process', url: 'https://drive.google.com/file/d/1M2xoiXDG30jI_BhO0CfaWRVJVxkPJWl3/view?usp=drive_link', thumb: 'video2_thumb' },
    ],
  },
  11: {
    title: "Video 3: Finding the Critical Error & Pro Tips",
    content: `Video 3 Finding the Critical Error:
This video explains how to identify the Critical Error in a model's trajectory.
• You will learn how to trace where the model went wrong and find the main mistake that caused the task to fail.
• It covers:
○ How to review the model's thoughts and actions step-by-step.
○ How to spot the exact step where the model diverged from the correct path.
○ How to confirm the Critical Error using the Error Categorization (EC) Library.
○ How to use the Ctrl+F function to verify the error mistake

Goal:
By the end of this video, you'll know how to track and mark the Critical Error accurately, ensuring each failure is classified based on its true cause.`,
    videos: [
      { name: 'Video 3 - Tracking the Critical Error', url: 'https://drive.google.com/file/d/1UqiPQ-0NCNB3ba3g5emssNltapH5Op0j/view?usp=drive_link', thumb: 'video3_thumb' }
    ],
    proTips: true
  }
};

const qaInfoBoxText = {
  1: "Understanding your role as an annotator is crucial for model improvement.",
  2: "The EC Example Library is your most important reference document.",
  3: "These are the four possible outcomes for any task.",
  4: "Clear status definitions help maintain consistency across evaluations.",
  5: "Finding the critical error is key to accurate model evaluation.",
  6: "Trajectory status depends on where the error occurred in the process.",
  7: "Always verify AutoEval's decisions - human judgment is essential.",
  8: "Understanding the complete flow helps you become a better annotator.",
  9: "Watch this tutorial to see the annotation platform in action.",
  10: "Follow this QC process to ensure quality and consistency.",
  11: "Apply these pro tips and learn to find the true cause of failure."
};


// ========================================================================
// 2. H2H REVIEW CONTENT (7 Pages)
// ========================================================================
const h2hPageContent = {
  1: {
    title: "What is H2H Evaluation?",
    content: `H2H Evaluation (Head-to-Head Evaluation) compares two Al model outputs for the same prompt to determine which performs better from a user's perspective.

The comparison happens along two main dimensions:
1. Process - How the model executes the task (its step-by-step reasoning or trajectory).
2. Outcome - The quality, accuracy, and usefulness of the final result (the task output).

Annotators classify each comparison into one of six categories:
• A Strongly
• A Slightly
• Neutral
• B Slightly
• B Strongly
• Unsure

Definitions:
• Neutral: Both models are equally effective, or differences are too small to impact the user task.
• Unsure: The comparison cannot be made fairly due to non-model-related issues (e.g., infrastructure errors, bad prompts, or tool failures).`
  },
  2: {
    title: "Outcome Evaluation",
    content: `Outcome evaluation compares the final outputs produced by the models.
Annotators should divide each output into three parts to identify what type of difference matters.

Categories of Output Information:
• Key Results: Core information directly tied to the task's main intent and explicit requirements.
  → Meaningful errors or omissions → Strongly classification
• Supplementary Information: Relevant, accurate, and useful additional details.
  → Minor missing or added information → Slightly classification
• Cosmetic Differences: Formatting, layout, or tone.
  → Do not count unless they affect meaning.

Focus on What Matters:
• Consider user impact: would the difference meaningfully change the user's experience or understanding?
• Cosmetic differences such as emojis, spacing, or stylistic phrasing should not influence outcome preference.
• Do Not Count: Differences like emojis, spacing, tone, or presentation.`
  },
  3: {
    title: "Process Evaluation",
    content: `Process evaluation focuses on how each model performs the task — the actions taken, order of steps, and correctness of those actions.

Annotators Should:
• Verify whether both models reached all required pages or steps.
• Note mistakes such as skipped actions, hallucinations, or incorrect filters.
• Reward logical persistence when it helps complete the task.
• Penalize inefficiency only if it causes or results from mistakes.

Common Process Error Types:
• UI Grounding Mistake
• UI Hallucination
• Info Hallucination (visual)
• Temporal Mistake
• Early Stopping or Premature Ending
• Missed Filter or Page Steps

Persistence and Efficiency:
• Reward persistence that helps reach the correct outcome.
• Do not reward irrelevant persistence (e.g., scrolling far beyond the timeframe).
• Longer processes are acceptable if accurate; penalize only when inefficiency stems from mistakes.
• If both models make similar mistakes and one takes more steps → Neutral.`
  },
  4: {
    title: "Note Format & Neutral vs. Unsure",
    content: `Preferred Note Format:
- Both models did X / did not fulfill key requirements by missing out on...
- Model A fulfilled supplementary requirements by giving information about... but Model B did not.
- Model A committed X error in Y step but Model B did not.
- Always include step numbers and error types (e.g., Step 3: UI Grounding Error).

Example:
- In terms of key requirements, both models... failed to apply the "most recent" filter...
- In terms of supplementary information, Model A made time misunderstanding errors in steps 45 and 39...
- This led to temporal mislabeling in the output as well.
- Hence, Model B is slightly preferred as compared to Model A.

---
Neutral vs. Unsure:

Neutral:
Use when both models:
• Produce similar key and supplementary information, or
• Have differences too minor to affect user satisfaction.

Unsure:
Use when the comparison is invalid because of issues outside model control, such as:
• Bad or unclear prompts
• Cases where Tool error is critical (e.g., read_text_and_links failure)
• Infrastructure issues (timeouts, unresponsive sites)
Example: "Infrastructure failure - website timeout, bot issue, run crash"`
  },
  5: {
    title: "Persistence & Common Errors",
    content: `Persistence and Efficiency Guidelines:
• Reward persistence when logical and directed at task completion.
• Do not reward persistence that goes beyond scope or repeats actions unnecessarily.
• Longer but correct trajectories should not be penalized.
• If both processes make similar errors but differ only in length → mark Neutral.

Common Errors and Pitfalls:
• Process: Preferring shorter trajectory blindly.
  → Correct: Only penalize inefficiency tied to mistakes.
• Process: Missing step numbers.
  → Correct: Always include step numbers and specify error types.
• Outcome: Over-weighting cosmetic differences.
  → Correct: Ignore formatting, emojis, or tone.
• Outcome: Vague reasoning ("A had more info").
  → Correct: Specify what information made the difference.
• All: Annotating wrong model.
  → Correct: Ensure reasoning matches selected preference.`
  },
  6: {
    title: "Golden Set & Best Practices",
    content: `Golden Set and Calibration:
A Golden Set of H2H examples is collected weekly to ensure consistency and quality.
Each batch should include:
• Both Process and Outcome annotations
• Examples of Neutral, Slightly, and Strongly classifications
• Diverse prompts and model comparisons
These serve as the reference for evaluating annotation accuracy and alignment.

Final Notes and Best Practices:
• Always align written reasoning with the selected preference.
• Think from the user's perspective - what difference would they care about?
• Separate Process and Outcome reasoning clearly.
• When in doubt or facing unclear prompts, request clarification early.
• If both models perform identically, select Neutral.
• Use the multi-line reasoning format for clarity and professionalism.
• Avoid vague phrases like "A had more info" — always specify what and why.`
  },
  7: {
    title: "Quick Reference",
    content: `Classification Summary:
• Strongly (A/B): Major factual or process differences. Focus on Key Results or crucial steps.
• Slightly (A/B): Minor yet meaningful differences. Focus on Supplementary info or small process edge.
• Neutral: Comparable results or equally flawed. User would not notice difference.
• Unsure: Non-model issue (tool/prompt/infrastructure). Invalid comparison.

Example Reasoning Structures:

Process Example:
- In terms of key steps, both models followed similar trajectories.
- However, Model A correctly applied the date and price filters, while Model B missed the date filter entirely.
- Therefore, Model A is slightly better than Model B.

Outcome Example:
- Both outputs address the main task correctly. However, Model B adds detailed supplementary information about product variants, which enhances completeness.
- Therefore, Model B is slightly better than Model A.`
  }
};

const h2hInfoBoxText = {
  1: "H2H is about comparing two models (A vs B) on Process and Outcome.",
  2: "Focus on user impact. Key Results = Strong. Supplementary = Slight. Cosmetic = Ignore.",
  3: "Process is about *how* the model worked. Look for missed steps, errors, or hallucinations.",
  4: "Always use specific step numbers and error types in your reasoning. 'Neutral' and 'Unsure' are not the same.",
  5: "Don't penalize a model just for being longer. Only penalize inefficiency that comes from mistakes.",
  6: "Your reasoning must always match your final selection (A/B/Neutral). Think from the user's perspective.",
  7: "Use this summary as a quick check before finalizing your classification."
};


// ========================================================================
// 3. MAIN COMPONENT (Handles both workflows)
// ========================================================================
const OnboardingUI = () => {
  // 'qa' = Annotation Q&A, 'h2h' = H2H Review
  const [activeMode, setActiveMode] = useState('qa');
  
  // Separate page state for each workflow
  const [qaCurrentPage, setQaCurrentPage] = useState(1);
  const [h2hCurrentPage, setH2hCurrentPage] = useState(1);
  
  const [modalOpen, setModalOpen] = useState(false);
  const [modalContent, setModalContent] = useState({ type: '', url: '', title: '' });

  // --- Dynamic Content Logic ---
  const isQAMode = activeMode === 'qa';
  
  const totalPages = isQAMode ? 11 : 7;
  const currentPage = isQAMode ? qaCurrentPage : h2hCurrentPage;
  const setCurrentPage = isQAMode ? setQaCurrentPage : setH2hCurrentPage;
  const pageContent = isQAMode ? qaPageContent : h2hPageContent;
  const infoBoxText = isQAMode ? qaInfoBoxText : h2hInfoBoxText;
  
  const pageData = pageContent[currentPage];
  const currentInfoText = infoBoxText[currentPage];
  // -----------------------------

  const handlePageClick = (pageNum) => {
    setCurrentPage(pageNum);
  };

  const handleNext = () => {
    if (currentPage < totalPages) {
      setCurrentPage(currentPage + 1);
    }
  };

  const handlePrevious = () => {
    if (currentPage > 1) {
      setCurrentPage(currentPage - 1);
    }
  };

  const openModal = (type, url, title) => {
    setModalContent({ type, url, title });
    setModalOpen(true);
  };

  const closeModal = () => {
    setModalOpen(false);
    setModalContent({ type: '', url: '', title: '' });
  };

  // Switch mode and reset the *other* workflow's page to 1
  const switchMode = (mode) => {
    setActiveMode(mode);
    if (mode === 'qa') {
      setH2hCurrentPage(1); // Reset H2H page when switching to QA
    } else {
      setQaCurrentPage(1); // Reset QA page when switching to H2H
    }
  };

  return (
    <div className="min-h-screen bg-black">
      {/* Header: Logo, Tabs, and Page Numbers */}
      <header className="bg-gray-950 border-b border-gray-800 sticky top-0 z-10">
        {/* Top Row: Logo */}
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-4 flex justify-center">
          <img 
            src="/logo.png" 
            alt="Company Logo" 
            className="h-12 w-auto object-contain opacity-90"
          />
        </div>

        {/* Bottom Row: Tabs and Page Numbers */}
        <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 flex justify-between items-center">
          
          {/* Left Side: Tab Buttons */}
          <div className="flex space-x-2">
            <button
              onClick={() => switchMode('qa')}
              className={`py-3 px-4 font-medium rounded-t-lg transition-all ${
                activeMode === 'qa' 
                  ? 'text-blue-400 border-b-2 border-blue-400' 
                  : 'text-gray-500 hover:text-gray-300'
              }`}
            >
              Annotation Q&A
            </button>
            <button
              onClick={() => switchMode('h2h')}
              className={`py-3 px-4 font-medium rounded-t-lg transition-all ${
                activeMode === 'h2h' 
                  ? 'text-blue-400 border-b-2 border-blue-400' 
                  : 'text-gray-500 hover:text-gray-300'
              }`}
            >
              H2H Review
            </button>
          </div>

          {/* Right Side: Page Numbers */}
          <div className="flex items-center gap-1 sm:gap-2 overflow-x-auto pb-2">
            <span className="text-sm text-gray-500 mr-2 hidden sm:inline">Pages:</span>
            {[...Array(totalPages)].map((_, index) => {
              const pageNum = index + 1;
              return (
                <button
                  key={pageNum}
                  onClick={() => handlePageClick(pageNum)}
                  className={`flex-shrink-0 w-8 h-8 sm:w-10 sm:h-10 rounded-lg font-semibold transition-all duration-200 ${
                    currentPage === pageNum
                      ? 'bg-gradient-to-br from-[#163791] to-[#62AADE] text-white shadow-lg shadow-[#62AADE]/50 scale-110'
                      : 'bg-gray-800 text-gray-400 hover:bg-gray-700 hover:text-gray-200 hover:scale-105'
                  }`}
                >
                  {pageNum}
                </button>
              );
            })}
          </div>
        </div>
      </header>

      {/* Main Content Area */}
      <main className="max-w-5xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <div className="bg-gray-900 rounded-2xl shadow-2xl border border-gray-800 p-6 sm:p-8 min-h-[600px]">
          
          {/* Page Indicator */}
          <div className="text-sm text-gray-500 mb-6 flex items-center justify-between">
            <span>Page {currentPage} of {totalPages}</span>
            <span className="text-[#62AADE]">
              {isQAMode ? "Workflow for New Joiners" : "H2H Evaluation Guide"}
            </span>
          </div>
          
          {/* Dynamic Content */}
          {pageData && (
            <div className="prose prose-invert max-w-none">
              <h1 className="text-3xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-[#62AADE] to-[#163791] mb-6">
                {pageData.title}
              </h1>
              <div className="text-base text-gray-300 leading-relaxed whitespace-pre-line">
                {pageData.content}
              </div>
              
              {/* --- Optional Blocks --- */}
              {pageData.docs && (
                <div className="mt-6 space-y-3">
                  {pageData.docs.map((doc, index) => (
                    <button key={index} onClick={() => openModal('doc', doc.url, doc.name)} className="w-full inline-flex items-center justify-center gap-2 px-5 py-3 bg-gradient-to-r from-[#163791] to-[#62AADE] text-white rounded-lg hover:shadow-lg hover:shadow-[#62AADE]/30 transition-all duration-200">
                      <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" /></svg>
                      View {doc.name}
                    </button>
                  ))}
                </div>
              )}
              {pageData.image && (
                <div className="mt-6">
                  <button onClick={() => openModal('image', pageData.image, 'View Image')} className="w-full bg-gray-800 rounded-lg p-4 border border-gray-700 hover:border-[#62AADE] transition-all cursor-pointer">
                    <div className="aspect-video bg-gray-900 rounded-lg flex items-center justify-center overflow-hidden">
                      <img src={`/${pageData.image}.png`} alt="Thumbnail" className="w-full h-full object-cover transition-transform duration-300 hover:scale-105"/>
                    </div>
                    <p className="text-sm text-gray-400 text-center mt-3">Click to view image</p>
                  </button>
                </div>
              )}
              {pageData.videos && (
                <div className="mt-6 space-y-4">
                  {pageData.videos.map((video, index) => (
                    <button key={index} onClick={() => openModal('video', video.url, video.name)} className="w-full bg-gray-800 rounded-lg p-4 border border-gray-700 hover:border-[#62AADE] transition-all cursor-pointer">
                      <div className="aspect-video bg-gray-900 rounded-lg flex items-center justify-center overflow-hidden relative">
                        {video.thumb ? (<img src={`/${video.thumb}.png`} alt={video.name} className="w-full h-full object-cover transition-transform duration-300 hover:scale-105"/>) : (<svg xmlns="http://www.w3.org/2000/svg" className="h-16 w-16 text-[#62AADE]" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" /><path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" /></svg>)}
                        <div className="absolute inset-0 flex items-center justify-center bg-black/30">
                           <svg xmlns="http://www.w3.org/2000/svg" className="h-16 w-16 text-white/80" fill="currentColor" viewBox="0 0 20 20"><path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8.002v3.996a1 1 0 001.555.832l3.197-1.997a1 1 0 000-1.664l-3.197-1.997z" clipRule="evenodd" /></svg>
                        </div>
                      </div>
                      <p className="text-sm text-gray-300 font-medium text-center mt-3">{video.name}</p>
                    </button>
                  ))}
                </div>
              )}
              {pageData.proTips && (
                <div className="mt-8 bg-gradient-to-br from-[#163791]/20 to-[#62AADE]/20 rounded-xl border border-[#62AADE]/30 p-6">
                  <h3 className="text-xl font-bold text-[#62AADE] mb-4">Pro tips</h3>
                  <ul className="space-y-2 text-gray-300">
                    <li>• Task status reasoning and Primary error should be linked (if failure was broken link, find out where the broken link entered the trajectory)</li>
                    <li>• You are detectives, playing against AI and finding its faults. So need to do it intelligently</li>
                    <li>• Read the Error Categories document if you have any doubts. Or directly ask the doubts group!</li>
                    <li>• The yutori platform sometimes doesn't load - use VPN! - setting it to UK</li>
                    <li>• We work as reviewers, so we need to build that mindset (what value does a reviewer add?)</li>
                  </ul>
                </div>
              )}
            </div>
          )}

          {/* Additional info box */}
          <div className="mt-8 p-5 bg-gradient-to-br from-[#163791]/20 to-[#62AADE]/20 rounded-xl border border-[#62AADE]/30">
            <div className="flex items-start gap-3">
              <div className="w-2 h-2 bg-[#62AADE] rounded-full mt-2 flex-shrink-0"></div>
              {/* === TYPO FIX IS HERE === */}
              <p className="text-gray-300 text-sm">
                {currentInfoText}
              </p>
            </div>
          </div>
        </div>
      </main>

      {/* Navigation Footer */}
      <footer className="max-w-5xl mx-auto px-4 sm:px-6 lg:px-8 py-6">
        <div className="flex justify-between items-center mb-6">
          <button
            onClick={handlePrevious}
            disabled={currentPage === 1}
            className={`px-6 py-3 rounded-lg font-medium transition-all duration-200 ${
              currentPage === 1
                ? 'bg-gray-900 text-gray-600 cursor-not-allowed border border-gray-800'
                : 'bg-gray-900 text-gray-300 border-2 border-gray-700 hover:border-[#62AADE] hover:text-[#62AADE] shadow-sm hover:shadow-md'
            }`}
          >
            ← Previous
          </button>

          <div className="text-sm text-gray-500">
            Progress: {Math.round((currentPage / totalPages) * 100)}%
          </div>

          <button
            onClick={handleNext}
            disabled={currentPage === totalPages}
            className={`px-6 py-3 rounded-lg font-medium transition-all duration-200 ${
              currentPage === totalPages
                ? 'bg-gray-900 text-gray-600 cursor-not-allowed border border-gray-800'
                : 'bg-gradient-to-r from-[#163791] to-[#62AADE] text-white hover:shadow-lg hover:shadow-[#62AADE]/30'
            }`}
          >
            {currentPage === totalPages ? 'Finish' : 'Next →'}
          </button>
        </div>

        <p className="text-center text-sm text-gray-600">
          Your Onboarding Buddy • Powered by RAG & AI
        </p>
      </footer>
      
      {/* Modal (Shared) */}
      {modalOpen && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/90 backdrop-blur-sm p-4">
          <div className="relative w-full h-full max-w-7xl max-h-[95vh] bg-gray-900 rounded-xl shadow-2xl border border-gray-700 flex flex-col">
            <div className="flex items-center justify-between p-4 border-b border-gray-800 flex-shrink-0">
              <h2 className="text-xl font-semibold text-white truncate">
                {modalContent.title}
              </h2>
              <button
                onClick={closeModal}
                className="p-2 hover:bg-gray-800 rounded-lg transition-colors flex-shrink-0"
              >
                <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 text-gray-400 hover:text-white" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" /></svg>
              </button>
            </div>
            
            <div className="flex-1 overflow-hidden p-1 sm:p-4">
              {modalContent.type === 'doc' && (
                <iframe
                  src={modalContent.url}
                  className="w-full h-full rounded-lg bg-white"
                  title={modalContent.title}
                />
              )}
              {modalContent.type === 'video' && (
                <iframe
                  src={modalContent.url.replace('/view?usp=drive_link', '/preview')}
                  className="w-full h-full rounded-lg"
                  title={modalContent.title}
                  allow="autoplay; encrypted-media"
                  allowFullScreen
                />
              )}
              {modalContent.type === 'image' && (
                <div className="w-full h-full flex items-center justify-center p-4">
                  <img
                    src={`/${modalContent.url}.png`}
                    alt={modalContent.title}
                    className="max-w-full max-h-full object-contain rounded-lg"
                  />
                </div>
              )}
            </div>
          </div>
        </div>
      )}
    </div>
  );
};

export default OnboardingUI;